{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models_jw\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from configs import paramsuper, getters\n",
    "\n",
    "device = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "args = paramsuper.ICIFARHashResNet18()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(0)\n",
    "\n",
    "#use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "#device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "training_period = 20000\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}# if use_cuda else {}\n",
    "train_loader = getters.get_dataset(args.dataset, training_period, args.batch_size, True, kwargs)\n",
    "\n",
    "import torch\n",
    "def prepare_fuzzy_z(time):\n",
    "    z = torch.zeros(10)\n",
    "    z[time] = 1\n",
    "    remaining_indices = [i for i in range(10) if i != time]\n",
    "    random_values = torch.rand(len(remaining_indices)) * 0.05\n",
    "    z[remaining_indices] = random_values\n",
    "    z /= z.sum()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for idxs, margin in enumerate([1,5,10,100]):\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(0)\n",
    "    net = models_jw.HashResNet18(10, device=device).to(device)\n",
    "    train_loader = getters.get_dataset(args.dataset, training_period, args.batch_size, True, kwargs)\n",
    "    test_loader = getters.get_dataset(args.dataset, 1, args.test_batch_size, False, kwargs)\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01)\n",
    "    TASKS_NUM = 5\n",
    "    for time in tqdm(range(TASKS_NUM*training_period)):\n",
    "        X, y = train_loader.get_data()\n",
    "        X, y = X.to(device), y.to(device)        \n",
    "        z = torch.zeros(10)\n",
    "        z[time // args.period] = 1\n",
    "        z = prepare_fuzzy_z(time // args.period)\n",
    "        y_hat, _, _ = net(X, z)\n",
    "        optimizer.zero_grad()\n",
    "        loss = hinge_loss(y_hat, y, margin)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(net.state_dict(), f\"trained_models/5_fuzzy_hlw_{margin}.pth\") #fuzzy-500\n",
    "\n",
    "\n",
    "    tasks_num = 10\n",
    "    accs =  {i: 0 for i in range(tasks_num)}\n",
    "    for time in tqdm(range(tasks_num)):\n",
    "        X, y = test_loader.get_data()\n",
    "        X, y = X.to(device), y.to(device)        \n",
    "        z = torch.zeros(10)\n",
    "        z[time] = 1\n",
    "        \n",
    "        y_hat, _, _ = net(X, z)\n",
    "        accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "    print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30131/100000 [48:55<1:35:29, 12.19it/s]"
     ]
    }
   ],
   "source": [
    "params = [[1000,900,800,300,250], [1000,900,800,700,600], [1000,500,400,300,250], [500,400,300,200,100], [100,200,300,400,500]]\n",
    "\n",
    "#all 100,90,80,70,60\n",
    "for idxs, margin in enumerate([[80,90,100,110,120], [80,70,60,50,40], [80,80,80,80,80], [80,75,70,65,60]]):\n",
    "    net = models_jw.HashResNet18(10, device=device).to(device)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(0)\n",
    "    train_loader = getters.get_dataset(args.dataset, training_period, args.batch_size, True, kwargs)\n",
    "    test_loader = getters.get_dataset(args.dataset, 1, args.test_batch_size, False, kwargs)\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01)\n",
    "    TASKS_NUM = 5\n",
    "    for time in tqdm(range(TASKS_NUM*training_period)):\n",
    "        X, y = train_loader.get_data()\n",
    "        X, y = X.to(device), y.to(device)        \n",
    "        z = torch.zeros(10)\n",
    "        z[time // args.period] = 1\n",
    "        #z = prepare_fuzzy_z(time // args.period)\n",
    "        y_hat, _, _ = net(X, z)\n",
    "        optimizer.zero_grad()\n",
    "        celoss = nn.CrossEntropyLoss()\n",
    "\n",
    "        marigin_idx = time // args.period - 1 \n",
    "        #margin = [1000,900,800,300,250] # decreasing nonlinear [1500,500,400,300,250]\n",
    "\n",
    "        loss = hinge_loss(y_hat, y, margin[marigin_idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(net.state_dict(), f\"trained_models/5_all{idxs}.pth\") #fuzzy-500\n",
    "\n",
    "\n",
    "    tasks_num = 10\n",
    "    accs =  {i: 0 for i in range(tasks_num)}\n",
    "    for time in tqdm(range(tasks_num)):\n",
    "        X, y = test_loader.get_data()\n",
    "        X, y = X.to(device), y.to(device)        \n",
    "        z = torch.zeros(10)\n",
    "        z[time] = 1\n",
    "        \n",
    "        y_hat, _, _ = net(X, z)\n",
    "        accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "    print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0275, 0.0528, 0.0456, 0.0607, 0.0073, 0.6825, 0.0118, 0.0544, 0.0080,\n",
      "        0.0496])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def prepare_fuzzy_z(time):\n",
    "    z = torch.zeros(10)\n",
    "    time = 5\n",
    "    z[time] = 1\n",
    "    remaining_indices = [i for i in range(10) if i != time]\n",
    "    random_values = torch.rand(len(remaining_indices)) * 0.1\n",
    "    z[remaining_indices] = random_values\n",
    "    z /= z.sum()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IDEAS\n",
    "- softmax z\n",
    "- entropy over tasks\n",
    "- noisy z during training\n",
    "- contexts with spikes\n",
    "- decreasing marigin in hinge\n",
    "- square-square loss\n",
    "- stability gap check\n",
    "- most distant contexts\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(0)\n",
    "\n",
    "net2 = models_jw.HashResNet18(10).to(device)\n",
    "net2.load_state_dict(torch.load(\"trained_models/5_7.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 619, 1: 519, 2: 655, 3: 598, 4: 691, 5: 102, 6: 73, 7: 106, 8: 100, 9: 100}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = getters.get_dataset(args.dataset, 1, args.test_batch_size, False, kwargs)\n",
    "tasks_num = 10\n",
    "accs =  {i: 0 for i in range(tasks_num)}\n",
    "for time in tqdm(range(tasks_num)):\n",
    "    X, y = test_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    z = torch.zeros(10)\n",
    "    z[time] = 1\n",
    "    y_hat, _, _ = net2(X, z)\n",
    "    accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 619, 1: 519, 2: 655, 3: 598, 4: 691, 5: 102, 6: 73, 7: 106, 8: 100, 9: 100}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATE WITH task_num\n",
    "\n",
    "test_loader = getters.get_dataset(args.dataset, 1, args.test_batch_size, False, kwargs)\n",
    "tasks_num = 10\n",
    "accs =  {i: 0 for i in range(tasks_num)}\n",
    "for time in tqdm(range(tasks_num)):\n",
    "    X, y = test_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    z = torch.zeros(10)\n",
    "    z[time] = 1\n",
    "    y_hat, _, _ = net2(X, z)\n",
    "    accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:24<00:00, 29.19s/it] \n"
     ]
    }
   ],
   "source": [
    "# EVALUATE WITHOUT task_num\n",
    "\n",
    "num_test = 10\n",
    "test_loader = getters.get_dataset(args.dataset, 1, 5, False, kwargs)\n",
    "accs_test =  {i: 0 for i in range(num_test)}\n",
    "\n",
    "zzz = {}\n",
    "for time in tqdm(range(num_test)):\n",
    "    X, y = test_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    y_hat, z, losses = net2(X)\n",
    "    zzz[time] = z \n",
    "    #accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "    accs_test[time] = accs_test[time] + (torch.tensor(y_hat) == y.to(\"cpu\")).sum().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [tensor([1.0000, 1.0000, 1.0000, 0.2499, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.0000, 0.1638, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.2980, 0.0295, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.0314, 0.1583, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.2913, 0.1365, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 1: [tensor([1.0000, 1.0000, 1.0000, 0.5481, 0.1226, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.4249, 0.2650, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.1965, 0.2387, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.3133, 0.0566, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 2: [tensor([1.0000, 1.0000, 1.0000, 0.6755, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.6047, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.4021, 0.1583, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0.8510, 1.0000, 1.0000, 1.0000, 0.8770, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 3: [tensor([1.0000, 1.0000, 1.0000, 0.5753, 0.2651, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 0.9031, 1.0000, 0.4321, 0.0693, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.8850, 0.0236, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0.6141, 1.0000, 1.0000, 0.2981, 0.0134, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0.8157, 1.0000, 1.0000, 0.9034, 0.0693, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 4: [tensor([1.0000, 1.0000, 1.0000, 0.2015, 0.4177, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.4967, 0.2350, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 0.8494, 0.4244, 0.0220, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.3283, 0.0376, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.7855, 0.0584, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 5: [tensor([1.0000, 1.0000, 1.0000, 0.5848, 0.0476, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.0395, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.3929, 0.0272, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 0.9386, 0.9648, 0.0650, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.0000, 0.7579, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 6: [tensor([1.0000, 1.0000, 1.0000, 0.4818, 0.1512, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.3256, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0.6446, 1.0000, 1.0000, 0.2203, 0.1312, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 0.0661, 0.0134, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(10, figsize=(20,5))\n",
    "for i in range(10):\n",
    "    axs[i].hist(torch.stack(zzz[i]).min(1).indices.cpu().numpy(), bins=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [tensor([ 1.3033,  4.3467, -0.6621, -0.7403, -0.6441, -0.4234, -0.9318, -0.5678,\n",
       "           0.2038, -0.8844], device='cuda:0'),\n",
       "  tensor([ 0.9704,  4.7921, -0.7192, -0.6246, -0.7366, -0.2269, -0.6769, -0.3177,\n",
       "          -0.5625, -0.8981], device='cuda:0'),\n",
       "  tensor([ 4.2421,  1.9055, -0.7806, -0.7036, -0.6371, -0.4943, -0.8196, -0.3552,\n",
       "          -0.6010, -0.7563], device='cuda:0'),\n",
       "  tensor([ 0.6117,  4.4417, -0.7328, -0.7208, -0.4382,  0.1496, -0.7525, -0.1378,\n",
       "          -0.8089, -0.6122], device='cuda:0'),\n",
       "  tensor([ 2.4357,  3.9742, -0.7581, -0.7301, -0.6253, -0.5732, -0.8430, -0.5383,\n",
       "          -0.5264, -0.8155], device='cuda:0')],\n",
       " 1: [tensor([ 0.4247,  4.4681, -0.7333, -0.3081, -0.4378, -0.3659, -0.3816, -0.4283,\n",
       "          -0.4997, -0.7382], device='cuda:0'),\n",
       "  tensor([ 2.6166,  3.2815, -0.9868, -0.6370, -0.4151, -0.8107, -0.8876, -0.4944,\n",
       "           0.0107, -0.6772], device='cuda:0'),\n",
       "  tensor([ 0.0691,  5.1877, -0.5070, -0.5021, -0.5395, -0.4053, -0.8805, -0.2722,\n",
       "          -0.5646, -0.5855], device='cuda:0'),\n",
       "  tensor([ 0.6946,  2.5279,  0.5435, -0.3706, -0.4143, -0.2730, -1.3101, -0.2137,\n",
       "           0.9909, -1.1752], device='cuda:0'),\n",
       "  tensor([ 0.4351,  4.4849, -0.7868, -0.6484, -0.3633, -0.8419, -0.7486, -0.3315,\n",
       "          -0.6965,  0.4970], device='cuda:0')],\n",
       " 2: [tensor([ 0.7950,  4.6039, -0.9175,  0.0811, -0.6992, -0.1918, -0.3343, -0.5499,\n",
       "          -0.7897, -0.9977], device='cuda:0'),\n",
       "  tensor([ 2.4809,  4.0948, -0.7398, -0.7902, -0.5545, -0.6794, -0.7122, -0.4815,\n",
       "          -0.6610, -0.9572], device='cuda:0'),\n",
       "  tensor([-0.2709,  4.8483, -0.5843, -0.6669, -0.1174, -0.4817, -0.4390, -0.4865,\n",
       "          -0.5385, -0.2632], device='cuda:0'),\n",
       "  tensor([ 0.8665,  4.8194, -1.0550, -0.0680, -0.3281, -0.9212, -0.9022, -0.7007,\n",
       "          -0.6995, -0.0114], device='cuda:0'),\n",
       "  tensor([ 1.1811,  4.0394, -0.1152, -0.5479, -0.1074, -0.5011, -0.6256, -0.6667,\n",
       "          -0.8604, -0.7962], device='cuda:0')],\n",
       " 3: [tensor([ 2.5447,  2.3458, -0.8205, -0.8502, -1.1849, -0.8235, -0.8222,  1.9305,\n",
       "          -0.7045, -0.6153], device='cuda:0'),\n",
       "  tensor([ 2.3813,  4.0704, -0.9395, -0.8391, -0.7197, -0.5153, -0.5435, -0.4294,\n",
       "          -0.5916, -0.8737], device='cuda:0'),\n",
       "  tensor([ 1.1953,  3.3131, -0.7660, -0.8124, -0.4117,  0.8738, -0.6200, -0.3341,\n",
       "          -0.6736, -0.7644], device='cuda:0'),\n",
       "  tensor([ 2.1767,  4.0208, -0.6538, -0.8124, -0.6049, -0.2558, -0.8713, -0.5902,\n",
       "          -0.7694, -0.6397], device='cuda:0'),\n",
       "  tensor([ 3.5205,  2.8943, -0.8135, -0.5590, -0.8864, -0.1971, -0.8566,  0.3234,\n",
       "          -1.2432, -1.1823], device='cuda:0')],\n",
       " 4: [tensor([ 1.3118,  4.2627, -0.4439, -0.9194, -0.7356,  0.1487, -0.7282, -0.4850,\n",
       "          -0.7245, -0.6867], device='cuda:0'),\n",
       "  tensor([ 2.0921,  3.9655, -0.9617, -0.8341, -0.2554, -0.7031, -0.5346, -0.3962,\n",
       "          -0.7540, -0.6186], device='cuda:0'),\n",
       "  tensor([ 0.3882,  4.9585, -0.7760, -0.5925, -0.5919, -0.4792, -0.4450, -0.4842,\n",
       "          -0.4297, -0.5481], device='cuda:0'),\n",
       "  tensor([ 0.9651,  2.4801, -0.8210, -0.8851, -0.0547, -0.5345, -0.2313,  0.0360,\n",
       "          -1.0228,  1.0682], device='cuda:0'),\n",
       "  tensor([ 2.6767,  3.0796, -0.5898, -0.5241, -0.5930, -0.8146, -0.8469, -0.1743,\n",
       "          -0.6439, -0.5698], device='cuda:0')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt #koń, pies, samolot\n",
    "# fig, axs = plt.subplots(10,figsize=(5,40))\n",
    "# for idx, i in enumerate(X[:10]):\n",
    "#     axs[idx].imshow(i.permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 1, 2: 0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-245.9485,   41.0720,  123.7339,  -20.3982,  -13.6119,    2.4594,\n",
       "           23.8586,   11.9880,   15.3942,  -23.4679], device='cuda:0'),\n",
       " tensor([-220.8584,    2.0477,  138.7914,  -26.9805,  -22.2933,   -4.6194,\n",
       "           26.4026,   11.6240,    6.5466,   -9.4133], device='cuda:0'),\n",
       " tensor([-213.2227,   20.5275,  144.8369,   -5.1570,   14.7023,   23.5151,\n",
       "           33.5397,   13.4607,   30.3790,    3.5353], device='cuda:0'),\n",
       " tensor([-213.2119,   50.4990,  157.6112,   13.9355,   -3.1974,    4.1927,\n",
       "           -2.4120,   44.0033,    9.7511,  -11.4271], device='cuda:0'),\n",
       " tensor([-215.6507,   42.1164,  148.8064,   -7.6765,  -30.4505,   -3.6351,\n",
       "            5.5471,    7.2766,    2.2397,  -24.2976], device='cuda:0')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.0614, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 1: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.5054, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 2: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 3: [tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 4: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.8724, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 5: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 6: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.6604, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 7: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.8913, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.8388, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.8762, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>)],\n",
       " 8: [tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)],\n",
       " 9: [tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.0982, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>),\n",
       "  tensor([0.0000, 1.0000, 1.0000, 1.0000, 0.6298, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000], device='cuda:0', grad_fn=<CatBackward0>),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<CatBackward0>)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3)\n",
    "for i in range(3):\n",
    "    axs[i].hist(torch.stack(zzz[i]).min(1).indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM 5 samples = 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = models_jw.HashResNet18(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (layer1): ModuleList(\n",
       "    (0-1): 2 x HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer2): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer3): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer4): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (linear): BinaryHashLinear()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((20,3,32,32), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9)],\n",
       " [tensor([ 0.3867,  1.7251, -2.1452,  1.6405,  1.8650, -0.2516, -0.1177, -0.6333,\n",
       "          -0.3887,  0.8633], device='cuda:0'),\n",
       "  tensor([-0.0706,  0.6241, -0.7360,  1.6453,  2.5672, -1.7667,  0.4365, -1.1464,\n",
       "           0.0431,  0.3689], device='cuda:0'),\n",
       "  tensor([ 0.1246,  1.6834, -1.1506,  1.3375,  2.3137, -1.2102, -0.0281, -0.8342,\n",
       "          -0.2544,  1.0565], device='cuda:0'),\n",
       "  tensor([ 0.1914,  2.1499, -0.2643,  1.0539,  1.9850, -1.1633, -0.0533, -0.1179,\n",
       "           0.6964,  0.6024], device='cuda:0'),\n",
       "  tensor([ 0.6807,  1.5459, -1.5954,  0.9104,  2.4229, -1.9098, -0.8851, -0.3445,\n",
       "          -0.3381,  0.7602], device='cuda:0'),\n",
       "  tensor([-0.5505,  1.9644, -1.0665,  1.6075,  2.0348, -0.4183, -0.2435, -0.8585,\n",
       "           0.1390,  0.6713], device='cuda:0'),\n",
       "  tensor([ 0.7799,  1.3138, -0.9207,  1.7433,  2.3234, -0.6825,  0.1990, -0.1293,\n",
       "          -0.8779,  0.7782], device='cuda:0'),\n",
       "  tensor([ 0.8788,  1.0570, -0.8200,  1.4384,  2.4120, -1.6772, -0.4965,  0.3740,\n",
       "          -0.1027,  0.7836], device='cuda:0'),\n",
       "  tensor([ 0.0429,  1.5774, -1.3967,  1.2432,  2.6253, -1.4149,  0.0804, -1.6232,\n",
       "          -0.2149,  0.8747], device='cuda:0'),\n",
       "  tensor([-0.0788,  2.1373, -0.8455,  0.7884,  2.3837, -0.6535,  0.0281, -0.6914,\n",
       "          -0.2771,  0.5807], device='cuda:0'),\n",
       "  tensor([ 0.1667,  0.9549, -1.0855,  0.9607,  2.8615, -1.2399,  0.3380, -0.1766,\n",
       "          -0.0780,  1.4476], device='cuda:0'),\n",
       "  tensor([ 0.8624,  1.6175, -0.6650,  0.6726,  2.6649, -0.7528,  0.0366, -1.1133,\n",
       "          -0.0029,  1.2394], device='cuda:0'),\n",
       "  tensor([ 0.8060,  1.6944, -1.7520,  0.6463,  1.3547, -1.0021, -0.1200, -0.6089,\n",
       "           0.5555,  1.6382], device='cuda:0'),\n",
       "  tensor([ 1.0236,  1.7261, -1.0950,  1.1129,  2.6095,  0.0694, -0.2898, -0.5892,\n",
       "           0.1888,  0.4980], device='cuda:0'),\n",
       "  tensor([ 1.2357,  1.2472,  0.1126,  1.0930,  1.8671, -0.9228, -0.2605, -0.7654,\n",
       "           0.4954,  0.9134], device='cuda:0'),\n",
       "  tensor([ 0.1823,  0.9197, -1.7656,  1.3958,  2.1991, -0.4111,  0.2993, -0.9178,\n",
       "           0.1159,  1.8332], device='cuda:0'),\n",
       "  tensor([ 0.7104,  1.6679, -0.2894,  1.6703,  1.9045, -1.1037, -0.0640, -0.1172,\n",
       "          -0.7472,  1.0001], device='cuda:0'),\n",
       "  tensor([ 0.0550,  1.1037, -1.2028,  1.4291,  2.4836, -0.3595,  0.1799,  0.2603,\n",
       "           0.4109,  1.0724], device='cuda:0'),\n",
       "  tensor([ 0.3766,  0.2113, -1.7346,  1.8158,  2.5938, -0.4781, -0.1668, -0.3841,\n",
       "          -0.1027,  0.5730], device='cuda:0'),\n",
       "  tensor([ 0.6439,  0.2379, -0.8861,  1.4888,  2.2068, -1.4532, -0.7745, -0.5813,\n",
       "          -0.3710,  1.5546], device='cuda:0')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(img)#, torch.ones(10, device=\"cuda\", requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = preds[-gt]\n",
    "proper_pred = torch.gather(y_hat, 1, gt.view(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[1,1.1,3,4], [5,6,-7,1]])\n",
    "gt = torch.tensor([0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.9000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss(y_hat, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(y_hat.size(), dtype=torch.bool)\n",
    "rows = torch.arange(y_hat.size(0))\n",
    "mask[rows, gt] = False\n",
    "y_hat_wrongs = y_hat[mask].reshape(y_hat.size(0), y_hat.size(1) - 1)\n",
    "torch.clamp(proper_pred - y_hat_wrongs + 1, min=0).sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 16.9066,  0.9249,  0.9669,  1.0736,  1.0238,  7.9881,  1.2362,\n",
       "         -0.1323,  1.1910]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat - proper_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3650, 16.5416,  0.5599,  0.6019,  0.7086,  0.6588,  7.6231,  0.8712,\n",
       "        -0.4973,  0.8260])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(tensor.size(1), dtype=torch.bool)\n",
    "mask[indices_to_delete] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0751, 0.0331, 0.0000, 0.0000, 0.0000, 0.0000, 1.1323,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(proper_pred - y_hat + 1, min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = -torch.tensor([[  0.3650, -16.5416,  -0.5599,  -0.6019,  -0.7086,  -0.6588,  -7.6231,\n",
    "         -0.8712,   0.4973,  -0.8260]])\n",
    "gt = torch.tensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msquare_square_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36msquare_square_loss\u001b[0;34m(y_hat, gt, margin)\u001b[0m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m y_hat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m proper_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(y_hat, \u001b[38;5;241m1\u001b[39m, gt\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 15\u001b[0m mean \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msum(y_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m proper_pred)\u001b[38;5;241m/\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m (proper_pred\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (mean \u001b[38;5;241m-\u001b[39m margin\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(mean))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36msquare_square_loss\u001b[0;34m(y_hat, gt, margin)\u001b[0m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m y_hat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m proper_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(y_hat, \u001b[38;5;241m1\u001b[39m, gt\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 15\u001b[0m mean \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msum(y_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m proper_pred)\u001b[38;5;241m/\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m (proper_pred\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (mean \u001b[38;5;241m-\u001b[39m margin\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(mean))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "square_square_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "square_square_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def inference(x, net, C=3):\n",
    "    min_value = float('inf')\n",
    "    min_x = None\n",
    "    min_y = None\n",
    "\n",
    "    def energy(z, y, x, net):\n",
    "        return net(x, z)[y]\n",
    "\n",
    "    def minimize_with_respect_to_z(y, x, net, lr=0.01, num_steps=1000):\n",
    "        z = torch.ones(C)/C\n",
    "        \n",
    "        optimizer = optim.SGD([z], lr=lr)\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            loss = energy(z, y, x, net)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return z.detach(), energy(z.detach(), y, x, net).detach()\n",
    "\n",
    "    for y in torch.arange(C):\n",
    "        x_min, e_min = minimize_with_respect_to_z(y, x, net)\n",
    "        if e_min < min_value:\n",
    "            min_value = e_min\n",
    "            min_x = x_min\n",
    "            min_y = y\n",
    "    \n",
    "    print(f\"Global minimum found at x = {min_x.item()}, y = {min_y.item()}, with E(x, y) = {min_value.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
