{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models_jw\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from configs import paramsuper, getters\n",
    "import torch\n",
    "args = paramsuper.ICIFARHashResNet18()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(0)\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "training_period = 20000\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = getters.get_dataset(args.dataset, training_period, args.batch_size, True, kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [1:23:27<00:00, 19.97it/s]\n"
     ]
    }
   ],
   "source": [
    "net = models_jw.HashResNet18(10).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01)\n",
    "TASKS_NUM = 5\n",
    "for time in tqdm(range(TASKS_NUM*training_period)):\n",
    "    X, y = train_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    z = torch.zeros(10)\n",
    "    z[time // args.period] = 1\n",
    "    y_hat, _, _ = net(X, z)\n",
    "    optimizer.zero_grad()\n",
    "    loss = hinge_loss(y_hat, y, 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"5_tasks_hunge10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(0)\n",
    "\n",
    "net2 = models_jw.HashResNet18(10).to(device)\n",
    "net2.load_state_dict(torch.load(\"5_tasks_hunge10.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 648, 1: 517, 2: 693, 3: 615, 4: 700, 5: 98, 6: 118, 7: 80, 8: 115, 9: 104}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATE WITH task_num\n",
    "\n",
    "test_loader = getters.get_dataset(args.dataset, 1, args.test_batch_size, False, kwargs)\n",
    "tasks_num = 10\n",
    "accs =  {i: 0 for i in range(tasks_num)}\n",
    "for time in tqdm(range(tasks_num)):\n",
    "    X, y = test_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    z = torch.zeros(10)\n",
    "    z[time] = 1\n",
    "    y_hat, _, _ = net2(X, z)\n",
    "    accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (576x10 and 5x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m test_loader\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m     10\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[0;32m---> 11\u001b[0m y_hat, z, losses \u001b[38;5;241m=\u001b[39m \u001b[43mnet2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m zzz[time] \u001b[38;5;241m=\u001b[39m z \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/models_jw.py:69\u001b[0m, in \u001b[0;36mHashResNet.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(x, z)\n",
      "File \u001b[0;32m~/superposition/models_jw.py:81\u001b[0m, in \u001b[0;36mHashResNet.optimize_z\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC):\n\u001b[1;32m     80\u001b[0m     debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 81\u001b[0m     z, e_min, losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_minimize_with_respect_to_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e_min \u001b[38;5;241m<\u001b[39m min_value:\n",
      "File \u001b[0;32m~/superposition/models_jw.py:61\u001b[0m, in \u001b[0;36mHashResNet._minimize_with_respect_to_z\u001b[0;34m(self, x, y, lr, num_steps)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 61\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menergy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/superposition/models_jw.py:51\u001b[0m, in \u001b[0;36mHashResNet.energy\u001b[0;34m(self, z, y, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menergy\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, y, x):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][y]\n",
      "File \u001b[0;32m~/superposition/models_jw.py:95\u001b[0m, in \u001b[0;36mHashResNet._forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z):\n\u001b[1;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m---> 95\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1[\u001b[38;5;241m1\u001b[39m](out, z)\n\u001b[1;32m     97\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2[\u001b[38;5;241m0\u001b[39m](out, z)\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/models_jw.py:129\u001b[0m, in \u001b[0;36mHashBasicBlock.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z):\n\u001b[0;32m--> 129\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    130\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out, z))\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/models_jw.py:187\u001b[0m, in \u001b[0;36mHashConv2d.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m     z_unsqueezed \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m     o \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz_unsqueezed\u001b[49m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    188\u001b[0m     o \u001b[38;5;241m=\u001b[39m o\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels,\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m*\u001b[39mo, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (576x10 and 5x1)"
     ]
    }
   ],
   "source": [
    "# EVALUATE WITHOUT task_num\n",
    "\n",
    "num_test = 10\n",
    "test_loader = getters.get_dataset(args.dataset, 1, 5, False, kwargs)\n",
    "accs_test =  {i: 0 for i in range(num_test)}\n",
    "\n",
    "zzz = {}\n",
    "for time in tqdm(range(num_test)):\n",
    "    X, y = test_loader.get_data()\n",
    "    X, y = X.to(device), y.to(device)        \n",
    "    y_hat, z, losses = net2(X)\n",
    "    zzz[time] = z \n",
    "    #accs[time] = accs[time] + (y_hat.min(1).indices==y).sum().item()\n",
    "    accs_test[time] = accs_test[time] + (torch.tensor(y_hat) == y.to(\"cpu\")).sum().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.8921, 0.0294, 0.0154, 0.0194, 0.0126, 0.0077, 0.0058, 0.0049, 0.0056,\n",
       "         0.0071], device='cuda:0'),\n",
       " tensor([0.9374, 0.0100, 0.0078, 0.0109, 0.0102, 0.0051, 0.0046, 0.0042, 0.0046,\n",
       "         0.0053], device='cuda:0'),\n",
       " tensor([0.7998, 0.0917, 0.0158, 0.0265, 0.0183, 0.0111, 0.0090, 0.0071, 0.0102,\n",
       "         0.0105], device='cuda:0'),\n",
       " tensor([0.6766, 0.1436, 0.0246, 0.0532, 0.0400, 0.0147, 0.0118, 0.0093, 0.0125,\n",
       "         0.0136], device='cuda:0'),\n",
       " tensor([0.5534, 0.2665, 0.0398, 0.0350, 0.0409, 0.0147, 0.0136, 0.0105, 0.0114,\n",
       "         0.0143], device='cuda:0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(10, figsize=(20,5))\n",
    "for i in range(10):\n",
    "    axs[i].hist(torch.stack(zzz[i]).min(1).indices.cpu().numpy(), bins=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [tensor([ 1.3033,  4.3467, -0.6621, -0.7403, -0.6441, -0.4234, -0.9318, -0.5678,\n",
       "           0.2038, -0.8844], device='cuda:0'),\n",
       "  tensor([ 0.9704,  4.7921, -0.7192, -0.6246, -0.7366, -0.2269, -0.6769, -0.3177,\n",
       "          -0.5625, -0.8981], device='cuda:0'),\n",
       "  tensor([ 4.2421,  1.9055, -0.7806, -0.7036, -0.6371, -0.4943, -0.8196, -0.3552,\n",
       "          -0.6010, -0.7563], device='cuda:0'),\n",
       "  tensor([ 0.6117,  4.4417, -0.7328, -0.7208, -0.4382,  0.1496, -0.7525, -0.1378,\n",
       "          -0.8089, -0.6122], device='cuda:0'),\n",
       "  tensor([ 2.4357,  3.9742, -0.7581, -0.7301, -0.6253, -0.5732, -0.8430, -0.5383,\n",
       "          -0.5264, -0.8155], device='cuda:0')],\n",
       " 1: [tensor([ 0.4247,  4.4681, -0.7333, -0.3081, -0.4378, -0.3659, -0.3816, -0.4283,\n",
       "          -0.4997, -0.7382], device='cuda:0'),\n",
       "  tensor([ 2.6166,  3.2815, -0.9868, -0.6370, -0.4151, -0.8107, -0.8876, -0.4944,\n",
       "           0.0107, -0.6772], device='cuda:0'),\n",
       "  tensor([ 0.0691,  5.1877, -0.5070, -0.5021, -0.5395, -0.4053, -0.8805, -0.2722,\n",
       "          -0.5646, -0.5855], device='cuda:0'),\n",
       "  tensor([ 0.6946,  2.5279,  0.5435, -0.3706, -0.4143, -0.2730, -1.3101, -0.2137,\n",
       "           0.9909, -1.1752], device='cuda:0'),\n",
       "  tensor([ 0.4351,  4.4849, -0.7868, -0.6484, -0.3633, -0.8419, -0.7486, -0.3315,\n",
       "          -0.6965,  0.4970], device='cuda:0')],\n",
       " 2: [tensor([ 0.7950,  4.6039, -0.9175,  0.0811, -0.6992, -0.1918, -0.3343, -0.5499,\n",
       "          -0.7897, -0.9977], device='cuda:0'),\n",
       "  tensor([ 2.4809,  4.0948, -0.7398, -0.7902, -0.5545, -0.6794, -0.7122, -0.4815,\n",
       "          -0.6610, -0.9572], device='cuda:0'),\n",
       "  tensor([-0.2709,  4.8483, -0.5843, -0.6669, -0.1174, -0.4817, -0.4390, -0.4865,\n",
       "          -0.5385, -0.2632], device='cuda:0'),\n",
       "  tensor([ 0.8665,  4.8194, -1.0550, -0.0680, -0.3281, -0.9212, -0.9022, -0.7007,\n",
       "          -0.6995, -0.0114], device='cuda:0'),\n",
       "  tensor([ 1.1811,  4.0394, -0.1152, -0.5479, -0.1074, -0.5011, -0.6256, -0.6667,\n",
       "          -0.8604, -0.7962], device='cuda:0')],\n",
       " 3: [tensor([ 2.5447,  2.3458, -0.8205, -0.8502, -1.1849, -0.8235, -0.8222,  1.9305,\n",
       "          -0.7045, -0.6153], device='cuda:0'),\n",
       "  tensor([ 2.3813,  4.0704, -0.9395, -0.8391, -0.7197, -0.5153, -0.5435, -0.4294,\n",
       "          -0.5916, -0.8737], device='cuda:0'),\n",
       "  tensor([ 1.1953,  3.3131, -0.7660, -0.8124, -0.4117,  0.8738, -0.6200, -0.3341,\n",
       "          -0.6736, -0.7644], device='cuda:0'),\n",
       "  tensor([ 2.1767,  4.0208, -0.6538, -0.8124, -0.6049, -0.2558, -0.8713, -0.5902,\n",
       "          -0.7694, -0.6397], device='cuda:0'),\n",
       "  tensor([ 3.5205,  2.8943, -0.8135, -0.5590, -0.8864, -0.1971, -0.8566,  0.3234,\n",
       "          -1.2432, -1.1823], device='cuda:0')],\n",
       " 4: [tensor([ 1.3118,  4.2627, -0.4439, -0.9194, -0.7356,  0.1487, -0.7282, -0.4850,\n",
       "          -0.7245, -0.6867], device='cuda:0'),\n",
       "  tensor([ 2.0921,  3.9655, -0.9617, -0.8341, -0.2554, -0.7031, -0.5346, -0.3962,\n",
       "          -0.7540, -0.6186], device='cuda:0'),\n",
       "  tensor([ 0.3882,  4.9585, -0.7760, -0.5925, -0.5919, -0.4792, -0.4450, -0.4842,\n",
       "          -0.4297, -0.5481], device='cuda:0'),\n",
       "  tensor([ 0.9651,  2.4801, -0.8210, -0.8851, -0.0547, -0.5345, -0.2313,  0.0360,\n",
       "          -1.0228,  1.0682], device='cuda:0'),\n",
       "  tensor([ 2.6767,  3.0796, -0.5898, -0.5241, -0.5930, -0.8146, -0.8469, -0.1743,\n",
       "          -0.6439, -0.5698], device='cuda:0')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt #koń, pies, samolot\n",
    "# fig, axs = plt.subplots(10,figsize=(5,40))\n",
    "# for idx, i in enumerate(X[:10]):\n",
    "#     axs[idx].imshow(i.permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 1, 2: 0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-245.9485,   41.0720,  123.7339,  -20.3982,  -13.6119,    2.4594,\n",
       "           23.8586,   11.9880,   15.3942,  -23.4679], device='cuda:0'),\n",
       " tensor([-220.8584,    2.0477,  138.7914,  -26.9805,  -22.2933,   -4.6194,\n",
       "           26.4026,   11.6240,    6.5466,   -9.4133], device='cuda:0'),\n",
       " tensor([-213.2227,   20.5275,  144.8369,   -5.1570,   14.7023,   23.5151,\n",
       "           33.5397,   13.4607,   30.3790,    3.5353], device='cuda:0'),\n",
       " tensor([-213.2119,   50.4990,  157.6112,   13.9355,   -3.1974,    4.1927,\n",
       "           -2.4120,   44.0033,    9.7511,  -11.4271], device='cuda:0'),\n",
       " tensor([-215.6507,   42.1164,  148.8064,   -7.6765,  -30.4505,   -3.6351,\n",
       "            5.5471,    7.2766,    2.2397,  -24.2976], device='cuda:0')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      3\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39mhist(torch\u001b[38;5;241m.\u001b[39mstack(zzz[i])\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "for i in range(3):\n",
    "    axs[i].hist(torch.stack(zzz[i]).min(1).indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM 5 samples = 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = models_jw.HashResNet18(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (layer1): ModuleList(\n",
       "    (0-1): 2 x HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer2): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer3): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (layer4): ModuleList(\n",
       "    (0): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList(\n",
       "        (0): HashConv2d()\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): HashBasicBlock(\n",
       "      (conv1): HashConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): HashConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (shortcut): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (linear): BinaryHashLinear()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((20,3,32,32), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(9)],\n",
       " [tensor([ 0.3867,  1.7251, -2.1452,  1.6405,  1.8650, -0.2516, -0.1177, -0.6333,\n",
       "          -0.3887,  0.8633], device='cuda:0'),\n",
       "  tensor([-0.0706,  0.6241, -0.7360,  1.6453,  2.5672, -1.7667,  0.4365, -1.1464,\n",
       "           0.0431,  0.3689], device='cuda:0'),\n",
       "  tensor([ 0.1246,  1.6834, -1.1506,  1.3375,  2.3137, -1.2102, -0.0281, -0.8342,\n",
       "          -0.2544,  1.0565], device='cuda:0'),\n",
       "  tensor([ 0.1914,  2.1499, -0.2643,  1.0539,  1.9850, -1.1633, -0.0533, -0.1179,\n",
       "           0.6964,  0.6024], device='cuda:0'),\n",
       "  tensor([ 0.6807,  1.5459, -1.5954,  0.9104,  2.4229, -1.9098, -0.8851, -0.3445,\n",
       "          -0.3381,  0.7602], device='cuda:0'),\n",
       "  tensor([-0.5505,  1.9644, -1.0665,  1.6075,  2.0348, -0.4183, -0.2435, -0.8585,\n",
       "           0.1390,  0.6713], device='cuda:0'),\n",
       "  tensor([ 0.7799,  1.3138, -0.9207,  1.7433,  2.3234, -0.6825,  0.1990, -0.1293,\n",
       "          -0.8779,  0.7782], device='cuda:0'),\n",
       "  tensor([ 0.8788,  1.0570, -0.8200,  1.4384,  2.4120, -1.6772, -0.4965,  0.3740,\n",
       "          -0.1027,  0.7836], device='cuda:0'),\n",
       "  tensor([ 0.0429,  1.5774, -1.3967,  1.2432,  2.6253, -1.4149,  0.0804, -1.6232,\n",
       "          -0.2149,  0.8747], device='cuda:0'),\n",
       "  tensor([-0.0788,  2.1373, -0.8455,  0.7884,  2.3837, -0.6535,  0.0281, -0.6914,\n",
       "          -0.2771,  0.5807], device='cuda:0'),\n",
       "  tensor([ 0.1667,  0.9549, -1.0855,  0.9607,  2.8615, -1.2399,  0.3380, -0.1766,\n",
       "          -0.0780,  1.4476], device='cuda:0'),\n",
       "  tensor([ 0.8624,  1.6175, -0.6650,  0.6726,  2.6649, -0.7528,  0.0366, -1.1133,\n",
       "          -0.0029,  1.2394], device='cuda:0'),\n",
       "  tensor([ 0.8060,  1.6944, -1.7520,  0.6463,  1.3547, -1.0021, -0.1200, -0.6089,\n",
       "           0.5555,  1.6382], device='cuda:0'),\n",
       "  tensor([ 1.0236,  1.7261, -1.0950,  1.1129,  2.6095,  0.0694, -0.2898, -0.5892,\n",
       "           0.1888,  0.4980], device='cuda:0'),\n",
       "  tensor([ 1.2357,  1.2472,  0.1126,  1.0930,  1.8671, -0.9228, -0.2605, -0.7654,\n",
       "           0.4954,  0.9134], device='cuda:0'),\n",
       "  tensor([ 0.1823,  0.9197, -1.7656,  1.3958,  2.1991, -0.4111,  0.2993, -0.9178,\n",
       "           0.1159,  1.8332], device='cuda:0'),\n",
       "  tensor([ 0.7104,  1.6679, -0.2894,  1.6703,  1.9045, -1.1037, -0.0640, -0.1172,\n",
       "          -0.7472,  1.0001], device='cuda:0'),\n",
       "  tensor([ 0.0550,  1.1037, -1.2028,  1.4291,  2.4836, -0.3595,  0.1799,  0.2603,\n",
       "           0.4109,  1.0724], device='cuda:0'),\n",
       "  tensor([ 0.3766,  0.2113, -1.7346,  1.8158,  2.5938, -0.4781, -0.1668, -0.3841,\n",
       "          -0.1027,  0.5730], device='cuda:0'),\n",
       "  tensor([ 0.6439,  0.2379, -0.8861,  1.4888,  2.2068, -1.4532, -0.7745, -0.5813,\n",
       "          -0.3710,  1.5546], device='cuda:0')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(img)#, torch.ones(10, device=\"cuda\", requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = preds[-gt]\n",
    "proper_pred = torch.gather(y_hat, 1, gt.view(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[1,1.1,3,4], [5,6,-7,1]])\n",
    "gt = torch.tensor([0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.9000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss(y_hat, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(y_hat.size(), dtype=torch.bool)\n",
    "rows = torch.arange(y_hat.size(0))\n",
    "mask[rows, gt] = False\n",
    "y_hat_wrongs = y_hat[mask].reshape(y_hat.size(0), y_hat.size(1) - 1)\n",
    "torch.clamp(proper_pred - y_hat_wrongs + 1, min=0).sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 16.9066,  0.9249,  0.9669,  1.0736,  1.0238,  7.9881,  1.2362,\n",
       "         -0.1323,  1.1910]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat - proper_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3650, 16.5416,  0.5599,  0.6019,  0.7086,  0.6588,  7.6231,  0.8712,\n",
       "        -0.4973,  0.8260])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(tensor.size(1), dtype=torch.bool)\n",
    "mask[indices_to_delete] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0751, 0.0331, 0.0000, 0.0000, 0.0000, 0.0000, 1.1323,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(proper_pred - y_hat + 1, min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = -torch.tensor([[  0.3650, -16.5416,  -0.5599,  -0.6019,  -0.7086,  -0.6588,  -7.6231,\n",
    "         -0.8712,   0.4973,  -0.8260]])\n",
    "gt = torch.tensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msquare_square_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36msquare_square_loss\u001b[0;34m(y_hat, gt, margin)\u001b[0m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m y_hat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m proper_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(y_hat, \u001b[38;5;241m1\u001b[39m, gt\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 15\u001b[0m mean \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msum(y_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m proper_pred)\u001b[38;5;241m/\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m (proper_pred\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (mean \u001b[38;5;241m-\u001b[39m margin\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(mean))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36msquare_square_loss\u001b[0;34m(y_hat, gt, margin)\u001b[0m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m y_hat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m proper_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(y_hat, \u001b[38;5;241m1\u001b[39m, gt\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 15\u001b[0m mean \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msum(y_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m proper_pred)\u001b[38;5;241m/\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m (proper_pred\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (mean \u001b[38;5;241m-\u001b[39m margin\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(mean))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/superposition/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "square_square_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "square_square_loss(preds, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def inference(x, net, C=3):\n",
    "    min_value = float('inf')\n",
    "    min_x = None\n",
    "    min_y = None\n",
    "\n",
    "    def energy(z, y, x, net):\n",
    "        return net(x, z)[y]\n",
    "\n",
    "    def minimize_with_respect_to_z(y, x, net, lr=0.01, num_steps=1000):\n",
    "        z = torch.ones(C)/C\n",
    "        \n",
    "        optimizer = optim.SGD([z], lr=lr)\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            loss = energy(z, y, x, net)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return z.detach(), energy(z.detach(), y, x, net).detach()\n",
    "\n",
    "    for y in torch.arange(C):\n",
    "        x_min, e_min = minimize_with_respect_to_z(y, x, net)\n",
    "        if e_min < min_value:\n",
    "            min_value = e_min\n",
    "            min_x = x_min\n",
    "            min_y = y\n",
    "    \n",
    "    print(f\"Global minimum found at x = {min_x.item()}, y = {min_y.item()}, with E(x, y) = {min_value.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
